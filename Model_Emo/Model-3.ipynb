{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Detection of Emotion of Speech for RAVDESS Audio Using Hybrid Convolution Neural Network\n\nhttps://www.hindawi.com/journals/jhe/2022/8472947/","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\nfrom datetime import datetime\nimport pickle\n\nimport librosa\nimport librosa.display\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch import optim as opt\nfrom torch.utils.data import Dataset, DataLoader \nimport torchvision\nfrom torchvision import transforms as T, datasets  \nfrom torch.utils.tensorboard import SummaryWriter \n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:48:50.226497Z","iopub.execute_input":"2022-06-18T10:48:50.226961Z","iopub.status.idle":"2022-06-18T10:48:54.579987Z","shell.execute_reply.started":"2022-06-18T10:48:50.226878Z","shell.execute_reply":"2022-06-18T10:48:54.579143Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"Ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/\"\nTess = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:00.722806Z","iopub.execute_input":"2022-06-18T10:49:00.724146Z","iopub.status.idle":"2022-06-18T10:49:00.728935Z","shell.execute_reply.started":"2022-06-18T10:49:00.724098Z","shell.execute_reply":"2022-06-18T10:49:00.728191Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ravdess_directory_list = os.listdir(Ravdess)\nravdess_emotion = ['neutral','calm','happy','sad','angry','fear','disgust','surprise']\n\nfile_emotion = []\nfile_path = []\nfor dir in ravdess_directory_list:\n    if (dir == \"audio_speech_actors_01-24\"):\n        continue\n    actor = os.listdir(Ravdess + dir)\n    for file in actor:\n        # get the emotion of this file\n        part = file.split('.')[0]\n        part = part.split('-')\n        id = int(part[2])\n        file_emotion.append(ravdess_emotion[id-1])\n        # get file's path\n        file_path.append(Ravdess + dir + '/' + file)\n        \n# convert to dataframe\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\npath_df = pd.DataFrame(file_path, columns=['Path'])\nRavdess_df = pd.concat([emotion_df, path_df], axis=1)\n\nRavdess_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:03.812607Z","iopub.execute_input":"2022-06-18T10:49:03.813158Z","iopub.status.idle":"2022-06-18T10:49:04.300784Z","shell.execute_reply.started":"2022-06-18T10:49:03.813113Z","shell.execute_reply":"2022-06-18T10:49:04.300037Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1440, 2)"},"metadata":{}}]},{"cell_type":"code","source":"tess_directory_list = os.listdir(Tess)\n\nfile_emotion = []\nfile_path = []\n\nfor dir in tess_directory_list:\n    directories = os.listdir(Tess + dir)\n    for file in directories:\n        part = file.split('.')[0]\n        part = part.split('_')[2]\n        if part=='ps':\n            file_emotion.append('surprise')\n        else:\n            file_emotion.append(part)\n        file_path.append(Tess + dir + '/' + file)\n        \n# convert to dataframe\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\npath_df = pd.DataFrame(file_path, columns=['Path'])\nTess_df = pd.concat([emotion_df, path_df], axis=1)\n\nTess_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:07.492082Z","iopub.execute_input":"2022-06-18T10:49:07.492618Z","iopub.status.idle":"2022-06-18T10:49:08.518146Z","shell.execute_reply.started":"2022-06-18T10:49:07.492575Z","shell.execute_reply":"2022-06-18T10:49:08.517428Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(2800, 2)"},"metadata":{}}]},{"cell_type":"code","source":"data_path = pd.concat([Ravdess_df, Tess_df], axis = 0)\ndata_path.to_csv(\"data_path.csv\",index=False)\ndata_path.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:11.792502Z","iopub.execute_input":"2022-06-18T10:49:11.793159Z","iopub.status.idle":"2022-06-18T10:49:11.832584Z","shell.execute_reply.started":"2022-06-18T10:49:11.793120Z","shell.execute_reply":"2022-06-18T10:49:11.831559Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Emotions                                               Path\n0  surprise  /kaggle/input/ravdess-emotional-speech-audio/A...\n1   neutral  /kaggle/input/ravdess-emotional-speech-audio/A...\n2   disgust  /kaggle/input/ravdess-emotional-speech-audio/A...\n3   disgust  /kaggle/input/ravdess-emotional-speech-audio/A...\n4   neutral  /kaggle/input/ravdess-emotional-speech-audio/A...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>surprise</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def extract_features(data,sample_rate):\n    result = np.array([])\n    \n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mfcc))\n    \n    # Log Mel-Spectrogram\n    mel = np.mean(librosa.feature.melspectrogram(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mel)) \n    \n    # Chroma\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S = np.abs(librosa.stft(data)), sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, chroma_stft))\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:14.932424Z","iopub.execute_input":"2022-06-18T10:49:14.932785Z","iopub.status.idle":"2022-06-18T10:49:14.939821Z","shell.execute_reply.started":"2022-06-18T10:49:14.932755Z","shell.execute_reply":"2022-06-18T10:49:14.938879Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.03 * np.random.uniform() * np.amax(data)\n    data = data + noise_amp * np.random.normal(size = data.shape[0])\n    return data\n\ndef pitch(data, sampling_rate, pitch_factor = 0.7):\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:42.493290Z","iopub.execute_input":"2022-06-18T10:49:42.493777Z","iopub.status.idle":"2022-06-18T10:49:42.500914Z","shell.execute_reply.started":"2022-06-18T10:49:42.493736Z","shell.execute_reply":"2022-06-18T10:49:42.500209Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\nfor path, emotion in zip(data_path.Path, data_path.Emotions):\n    # load data\n    data, sample_rate = librosa.load(path, duration=3)\n    \n    # augmentation\n    noise_data = noise(data)\n    pitch_data = pitch(data, sample_rate)\n    \n    # original speech\n    feature = extract_features(data, sample_rate)\n    feature = np.array(feature)\n    X.append(feature)\n    Y.append(emotion)\n    \n    # noise speech\n    feature_noise = extract_features(noise_data, sample_rate)\n    feature_noise = np.array(feature_noise)\n    X.append(feature_noise)\n    Y.append(emotion)\n    \n    # pitch speech\n    feature_pitch = extract_features(pitch_data, sample_rate)\n    feature_pitch = np.array(feature_pitch)\n    X.append(feature_pitch)\n    Y.append(emotion)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:49:48.930944Z","iopub.execute_input":"2022-06-18T10:49:48.931572Z","iopub.status.idle":"2022-06-18T11:12:14.107945Z","shell.execute_reply.started":"2022-06-18T10:49:48.931534Z","shell.execute_reply":"2022-06-18T11:12:14.106814Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# convert to df and save\nFeatures = pd.DataFrame(X)\nFeatures['labels'] = Y\nFeatures.to_csv('features.csv', index=False)\nFeatures.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:15:30.752523Z","iopub.execute_input":"2022-06-18T11:15:30.753108Z","iopub.status.idle":"2022-06-18T11:15:35.391175Z","shell.execute_reply.started":"2022-06-18T11:15:30.753071Z","shell.execute_reply":"2022-06-18T11:15:35.390282Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            0          1          2         3          4         5         6  \\\n0 -546.596863  44.377380 -19.342091  9.734666  -9.818512 -9.713405 -5.113235   \n1 -506.400634  38.243272 -17.707741  7.183844  -9.801996 -9.961390 -5.398600   \n2 -570.769043  42.897747 -20.612906  9.520269 -13.445296 -8.302529 -5.846328   \n3 -617.853333  61.302486 -15.036719  8.042834  -7.553607 -5.726502 -8.156550   \n4 -374.570737  16.911391  -0.257796 -0.946276  -3.302215 -4.228215 -5.007686   \n\n           7         8         9  ...       151       152       153       154  \\\n0  -6.843500 -4.441024 -4.307160  ...  0.471864  0.448686  0.505751  0.540664   \n1  -6.819918 -5.188599 -4.623633  ...  0.667220  0.691312  0.684664  0.690750   \n2  -6.734608 -5.509935 -4.831536  ...  0.483759  0.429982  0.501124  0.572247   \n3 -10.893152 -5.658010 -0.963206  ...  0.519677  0.492402  0.504126  0.517783   \n4  -5.444537 -3.429903 -1.826473  ...  0.811161  0.783862  0.701154  0.709390   \n\n        155       156       157       158       159    labels  \n0  0.537667  0.536776  0.541370  0.569535  0.598440  surprise  \n1  0.689066  0.691375  0.702380  0.734903  0.731455  surprise  \n2  0.574985  0.578177  0.579576  0.587847  0.613666  surprise  \n3  0.567078  0.568422  0.528793  0.507262  0.484923   neutral  \n4  0.743575  0.745451  0.740256  0.743368  0.735214   neutral  \n\n[5 rows x 161 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>151</th>\n      <th>152</th>\n      <th>153</th>\n      <th>154</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-546.596863</td>\n      <td>44.377380</td>\n      <td>-19.342091</td>\n      <td>9.734666</td>\n      <td>-9.818512</td>\n      <td>-9.713405</td>\n      <td>-5.113235</td>\n      <td>-6.843500</td>\n      <td>-4.441024</td>\n      <td>-4.307160</td>\n      <td>...</td>\n      <td>0.471864</td>\n      <td>0.448686</td>\n      <td>0.505751</td>\n      <td>0.540664</td>\n      <td>0.537667</td>\n      <td>0.536776</td>\n      <td>0.541370</td>\n      <td>0.569535</td>\n      <td>0.598440</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-506.400634</td>\n      <td>38.243272</td>\n      <td>-17.707741</td>\n      <td>7.183844</td>\n      <td>-9.801996</td>\n      <td>-9.961390</td>\n      <td>-5.398600</td>\n      <td>-6.819918</td>\n      <td>-5.188599</td>\n      <td>-4.623633</td>\n      <td>...</td>\n      <td>0.667220</td>\n      <td>0.691312</td>\n      <td>0.684664</td>\n      <td>0.690750</td>\n      <td>0.689066</td>\n      <td>0.691375</td>\n      <td>0.702380</td>\n      <td>0.734903</td>\n      <td>0.731455</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-570.769043</td>\n      <td>42.897747</td>\n      <td>-20.612906</td>\n      <td>9.520269</td>\n      <td>-13.445296</td>\n      <td>-8.302529</td>\n      <td>-5.846328</td>\n      <td>-6.734608</td>\n      <td>-5.509935</td>\n      <td>-4.831536</td>\n      <td>...</td>\n      <td>0.483759</td>\n      <td>0.429982</td>\n      <td>0.501124</td>\n      <td>0.572247</td>\n      <td>0.574985</td>\n      <td>0.578177</td>\n      <td>0.579576</td>\n      <td>0.587847</td>\n      <td>0.613666</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-617.853333</td>\n      <td>61.302486</td>\n      <td>-15.036719</td>\n      <td>8.042834</td>\n      <td>-7.553607</td>\n      <td>-5.726502</td>\n      <td>-8.156550</td>\n      <td>-10.893152</td>\n      <td>-5.658010</td>\n      <td>-0.963206</td>\n      <td>...</td>\n      <td>0.519677</td>\n      <td>0.492402</td>\n      <td>0.504126</td>\n      <td>0.517783</td>\n      <td>0.567078</td>\n      <td>0.568422</td>\n      <td>0.528793</td>\n      <td>0.507262</td>\n      <td>0.484923</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-374.570737</td>\n      <td>16.911391</td>\n      <td>-0.257796</td>\n      <td>-0.946276</td>\n      <td>-3.302215</td>\n      <td>-4.228215</td>\n      <td>-5.007686</td>\n      <td>-5.444537</td>\n      <td>-3.429903</td>\n      <td>-1.826473</td>\n      <td>...</td>\n      <td>0.811161</td>\n      <td>0.783862</td>\n      <td>0.701154</td>\n      <td>0.709390</td>\n      <td>0.743575</td>\n      <td>0.745451</td>\n      <td>0.740256</td>\n      <td>0.743368</td>\n      <td>0.735214</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 161 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load features from file\nFeatures = pd.read_csv(\"./features.csv\")\nX = Features.iloc[: ,:-1].values\nY = Features['labels'].values\nlen(X), len(Y), data_path.Path.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:00.097772Z","iopub.execute_input":"2022-06-18T13:19:00.098170Z","iopub.status.idle":"2022-06-18T13:19:00.594292Z","shell.execute_reply.started":"2022-06-18T13:19:00.098135Z","shell.execute_reply":"2022-06-18T13:19:00.593522Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(12720, 12720, (4240,))"},"metadata":{}}]},{"cell_type":"code","source":"# One hot endcoding for Y.\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:03.213769Z","iopub.execute_input":"2022-06-18T13:19:03.214363Z","iopub.status.idle":"2022-06-18T13:19:03.226371Z","shell.execute_reply.started":"2022-06-18T13:19:03.214329Z","shell.execute_reply":"2022-06-18T13:19:03.225525Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, random_state = 0, shuffle = True, test_size=0.3)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:06.875461Z","iopub.execute_input":"2022-06-18T13:19:06.876104Z","iopub.status.idle":"2022-06-18T13:19:06.901839Z","shell.execute_reply.started":"2022-06-18T13:19:06.876066Z","shell.execute_reply":"2022-06-18T13:19:06.901095Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"((8904, 160), (8904, 8), (3816, 160), (3816, 8))"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\n\n# scaling our data and save the scaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\n\npickle.dump(scaler, open('scaler_Hybrid-1.pkl','wb'))\nscaler = pickle.load(open('scaler_Hybrid-1.pkl','rb'))\n\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:10.927090Z","iopub.execute_input":"2022-06-18T13:19:10.927454Z","iopub.status.idle":"2022-06-18T13:19:10.954590Z","shell.execute_reply.started":"2022-06-18T13:19:10.927425Z","shell.execute_reply":"2022-06-18T13:19:10.953519Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"((8904, 160), (8904, 8), (3816, 160), (3816, 8))"},"metadata":{}}]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        X = torch.tensor(self.X[idx]).type(torch.float)\n        y = torch.tensor(self.y[idx]).type(torch.float)\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:27:20.291677Z","iopub.execute_input":"2022-06-18T12:27:20.292263Z","iopub.status.idle":"2022-06-18T12:27:20.297991Z","shell.execute_reply.started":"2022-06-18T12:27:20.292229Z","shell.execute_reply":"2022-06-18T12:27:20.297194Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#Convert X to tensor\nX_train_2 = torch.from_numpy(x_train)\nX_test_2 = torch.from_numpy(x_test)\nprint(X_train_2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:18.672390Z","iopub.execute_input":"2022-06-18T13:19:18.672757Z","iopub.status.idle":"2022-06-18T13:19:18.679257Z","shell.execute_reply.started":"2022-06-18T13:19:18.672727Z","shell.execute_reply":"2022-06-18T13:19:18.678443Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"torch.Size([8904, 160])\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 64\ntrain_data = Dataset(X_train_2, y_train)\ntest_data = Dataset(X_test_2, y_test)\n\ntrain_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:21.021021Z","iopub.execute_input":"2022-06-18T13:19:21.021742Z","iopub.status.idle":"2022-06-18T13:19:21.027292Z","shell.execute_reply.started":"2022-06-18T13:19:21.021700Z","shell.execute_reply":"2022-06-18T13:19:21.026293Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    \n    def __init__(self, ):\n        super(CNN, self).__init__()\n        \n        # Block #1: \n        self.layer1 = nn.Sequential(\n            nn.Conv1d(in_channels=1, out_channels=1024, kernel_size=5),\n            nn.ReLU()\n        )\n        \n        # Block #2: \n        self.layer2 = nn.Sequential(\n            nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=5),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=5, stride=2)\n        )\n        \n        \n        # Block #3: \n        self.layer3 = nn.Sequential(\n            nn.Conv1d(in_channels=512, out_channels=256, kernel_size=5),\n            nn.ReLU()\n        )\n        \n        # Block #4: \n        self.layer4 = nn.Sequential(\n            nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5),\n            nn.ReLU()\n        )\n        \n        # Block #5: \n        self.layer5 = nn.Sequential(\n            nn.Conv1d(in_channels=128, out_channels=64, kernel_size=5),\n            nn.ReLU()\n        )\n        \n        # Block #6:  \n        self.layer6 = nn.Sequential(\n            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=5, stride=2)\n        )\n        \n        # Block #7: \n        self.layer7 = nn.Sequential(\n            nn.Conv1d(in_channels=64, out_channels=32, kernel_size=5),\n            nn.ReLU()\n        )\n        \n        # Block #8: \n        self.layer8 = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=5),\n            nn.ReLU()\n        )\n\n        # FC 8 → softmax\n        self.fc = nn.Linear(in_features=16*19, out_features=8)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        \n        # Channel x H = 1 x 160\n        out = self.layer1(x.view(-1, 1, 160))\n        \n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        \n        out = out.view(out.size(0), -1) \n        out = self.fc(out)\n        out = self.softmax(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:27:45.090849Z","iopub.execute_input":"2022-06-18T12:27:45.091626Z","iopub.status.idle":"2022-06-18T12:27:45.106085Z","shell.execute_reply.started":"2022-06-18T12:27:45.091590Z","shell.execute_reply":"2022-06-18T12:27:45.104932Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# model = CNN()\n# print(model)\n# !pip install torch-summary\nfrom torchsummary import summary\n\nmodel = CNN()\nsummary(model, (64, 160))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:27:52.855961Z","iopub.execute_input":"2022-06-18T12:27:52.856314Z","iopub.status.idle":"2022-06-18T12:27:52.907083Z","shell.execute_reply.started":"2022-06-18T12:27:52.856284Z","shell.execute_reply":"2022-06-18T12:27:52.906148Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 1024, 156]           --\n|    └─Conv1d: 2-1                       [-1, 1024, 156]           6,144\n|    └─ReLU: 2-2                         [-1, 1024, 156]           --\n├─Sequential: 1-2                        [-1, 512, 74]             --\n|    └─Conv1d: 2-3                       [-1, 512, 152]            2,621,952\n|    └─BatchNorm1d: 2-4                  [-1, 512, 152]            1,024\n|    └─ReLU: 2-5                         [-1, 512, 152]            --\n|    └─MaxPool1d: 2-6                    [-1, 512, 74]             --\n├─Sequential: 1-3                        [-1, 256, 70]             --\n|    └─Conv1d: 2-7                       [-1, 256, 70]             655,616\n|    └─ReLU: 2-8                         [-1, 256, 70]             --\n├─Sequential: 1-4                        [-1, 128, 66]             --\n|    └─Conv1d: 2-9                       [-1, 128, 66]             163,968\n|    └─ReLU: 2-10                        [-1, 128, 66]             --\n├─Sequential: 1-5                        [-1, 64, 62]              --\n|    └─Conv1d: 2-11                      [-1, 64, 62]              41,024\n|    └─ReLU: 2-12                        [-1, 64, 62]              --\n├─Sequential: 1-6                        [-1, 64, 27]              --\n|    └─Conv1d: 2-13                      [-1, 64, 58]              20,544\n|    └─ReLU: 2-14                        [-1, 64, 58]              --\n|    └─MaxPool1d: 2-15                   [-1, 64, 27]              --\n├─Sequential: 1-7                        [-1, 32, 23]              --\n|    └─Conv1d: 2-16                      [-1, 32, 23]              10,272\n|    └─ReLU: 2-17                        [-1, 32, 23]              --\n├─Sequential: 1-8                        [-1, 16, 19]              --\n|    └─Conv1d: 2-18                      [-1, 16, 19]              2,576\n|    └─ReLU: 2-19                        [-1, 16, 19]              --\n├─Linear: 1-9                            [-1, 8]                   2,440\n├─Softmax: 1-10                          [-1, 8]                   --\n==========================================================================================\nTotal params: 3,525,560\nTrainable params: 3,525,560\nNon-trainable params: 0\nTotal mult-adds (M): 463.48\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 2.67\nParams size (MB): 13.45\nEstimated Total Size (MB): 16.16\n==========================================================================================\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 1024, 156]           --\n|    └─Conv1d: 2-1                       [-1, 1024, 156]           6,144\n|    └─ReLU: 2-2                         [-1, 1024, 156]           --\n├─Sequential: 1-2                        [-1, 512, 74]             --\n|    └─Conv1d: 2-3                       [-1, 512, 152]            2,621,952\n|    └─BatchNorm1d: 2-4                  [-1, 512, 152]            1,024\n|    └─ReLU: 2-5                         [-1, 512, 152]            --\n|    └─MaxPool1d: 2-6                    [-1, 512, 74]             --\n├─Sequential: 1-3                        [-1, 256, 70]             --\n|    └─Conv1d: 2-7                       [-1, 256, 70]             655,616\n|    └─ReLU: 2-8                         [-1, 256, 70]             --\n├─Sequential: 1-4                        [-1, 128, 66]             --\n|    └─Conv1d: 2-9                       [-1, 128, 66]             163,968\n|    └─ReLU: 2-10                        [-1, 128, 66]             --\n├─Sequential: 1-5                        [-1, 64, 62]              --\n|    └─Conv1d: 2-11                      [-1, 64, 62]              41,024\n|    └─ReLU: 2-12                        [-1, 64, 62]              --\n├─Sequential: 1-6                        [-1, 64, 27]              --\n|    └─Conv1d: 2-13                      [-1, 64, 58]              20,544\n|    └─ReLU: 2-14                        [-1, 64, 58]              --\n|    └─MaxPool1d: 2-15                   [-1, 64, 27]              --\n├─Sequential: 1-7                        [-1, 32, 23]              --\n|    └─Conv1d: 2-16                      [-1, 32, 23]              10,272\n|    └─ReLU: 2-17                        [-1, 32, 23]              --\n├─Sequential: 1-8                        [-1, 16, 19]              --\n|    └─Conv1d: 2-18                      [-1, 16, 19]              2,576\n|    └─ReLU: 2-19                        [-1, 16, 19]              --\n├─Linear: 1-9                            [-1, 8]                   2,440\n├─Softmax: 1-10                          [-1, 8]                   --\n==========================================================================================\nTotal params: 3,525,560\nTrainable params: 3,525,560\nNon-trainable params: 0\nTotal mult-adds (M): 463.48\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 2.67\nParams size (MB): 13.45\nEstimated Total Size (MB): 16.16\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nclass Trainer:\n    def __init__(self, train_dataloader, test_dataloader,\n                 model, loss_fn, optimizer, scheduler, logger, device='cpu'):\n        self.model = model.to(device)\n        self.train_dataloader = train_dataloader\n        self.test_dataloader = test_dataloader\n        self.logger = logger\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = device\n\n    def train_epoch(self):\n        # Train data\n        n_samples = len(self.train_dataloader.dataset)\n        train_loss = 0\n\n        for batch_idx, (X, y) in enumerate(self.train_dataloader):\n            X = X.to(self.device)\n            y = y.to(self.device)\n            # Forward\n            pred = self.model(X)\n            loss = self.loss_fn(pred, torch.argmax(y, dim=1))\n            \n            # Backward\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            train_loss += loss\n        self.scheduler.step()\n        return train_loss / n_samples\n\n    def test_epoch(self):\n        # Test data\n        n_samples = len(self.test_dataloader.dataset)\n        test_loss = 0\n\n        for batch_idx, (X,y) in enumerate(self.test_dataloader):\n            X = X.to(self.device)\n            y = y.to(self.device)\n            with torch.no_grad():\n                # Forward\n                pred = self.model(X)\n                loss = self.loss_fn(pred, torch.argmax(y, dim=1))\n\n            test_loss += loss\n\n        return test_loss / n_samples\n\n    def evaluation(self, dataloader):\n        y_true = []\n        y_pred = []\n        for X, y in dataloader:\n            X = X.to(self.device)\n            y_true.append(y.detach().cpu())\n            y_pred.append(self.model(X).detach().cpu())\n        \n        y_true = torch.cat(y_true, dim=0)\n        y_pred = torch.cat(y_pred, dim=0)\n\n        true_labels = torch.argmax(y_true, dim=1)\n        pred_labels = torch.argmax(y_pred, dim=1)\n        accuracy = accuracy_score(true_labels.cpu(), pred_labels.cpu())\n\n        return accuracy\n\n    def train(self, epochs=10):\n        for i in range(epochs):\n            self.current_epoch = i+1\n            # Training\n            train_loss = self.train_epoch()\n            test_loss = self.test_epoch()\n\n            # Evaluation\n            train_acc = self.evaluation(self.train_dataloader)\n            test_acc = self.evaluation(self.test_dataloader)\n            \n            # Logging\n            self.logger.add_scalar('Loss/train', train_loss.item(), i+1)\n            self.logger.add_scalar('Loss/test', test_loss.item(), i+1)\n            self.logger.add_scalar('Accuracy/train', train_acc.item(), i+1)\n            self.logger.add_scalar('Accuracy/test', test_acc.item(), i+1)\n\n            ## Log histogram\n            for name, params in model.named_parameters():\n                if 'weight' in name:\n                    self.logger.add_histogram(name, params, i+1)\n\n            # if ((i+1) % 10 == 0):\n            print(f\"Epoch {i+1}: Train Loss = {train_loss.item():.5f}, Test Loss = {test_loss.item():.5f}, \"\n            f\"Train accuracy score = {train_acc.item():.5f}, Test accuracy score = {test_acc.item():.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-18T12:27:59.065721Z","iopub.execute_input":"2022-06-18T12:27:59.066140Z","iopub.status.idle":"2022-06-18T12:27:59.086731Z","shell.execute_reply.started":"2022-06-18T12:27:59.066106Z","shell.execute_reply":"2022-06-18T12:27:59.085937Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 1e-3\nLOG_DIR = \"./logs/\"\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:32.940421Z","iopub.execute_input":"2022-06-18T13:19:32.940790Z","iopub.status.idle":"2022-06-18T13:19:32.946727Z","shell.execute_reply.started":"2022-06-18T13:19:32.940759Z","shell.execute_reply":"2022-06-18T13:19:32.945796Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\n\nmodel = CNN()\nloss_fn = nn.CrossEntropyLoss() \noptimizer = opt.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = opt.lr_scheduler.StepLR(optimizer, step_size=20, gamma=1, last_epoch=- 1, verbose=False)\nlogger = SummaryWriter(os.path.join(LOG_DIR, datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\"))) # Logger\n\n# Trainer\ntrainer = Trainer(\n    train_dataloader=train_dataloader,\n    test_dataloader=test_dataloader,\n    model=model,\n    loss_fn=loss_fn,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    logger=logger,\n    device=DEVICE\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:35.582123Z","iopub.execute_input":"2022-06-18T13:19:35.582480Z","iopub.status.idle":"2022-06-18T13:19:35.624241Z","shell.execute_reply.started":"2022-06-18T13:19:35.582450Z","shell.execute_reply":"2022-06-18T13:19:35.623510Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\ntrainer.train(epochs=15)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:19:39.387805Z","iopub.execute_input":"2022-06-18T13:19:39.388453Z","iopub.status.idle":"2022-06-18T13:21:19.042603Z","shell.execute_reply.started":"2022-06-18T13:19:39.388415Z","shell.execute_reply":"2022-06-18T13:21:19.041521Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 0.03100, Test Loss = 0.03078, Train accuracy score = 0.30323, Test accuracy score = 0.29271\nEpoch 2: Train Loss = 0.03039, Test Loss = 0.02992, Train accuracy score = 0.38039, Test accuracy score = 0.36845\nEpoch 3: Train Loss = 0.03029, Test Loss = 0.03070, Train accuracy score = 0.32233, Test accuracy score = 0.31840\nEpoch 4: Train Loss = 0.03053, Test Loss = 0.03043, Train accuracy score = 0.35355, Test accuracy score = 0.33281\nEpoch 5: Train Loss = 0.03057, Test Loss = 0.03101, Train accuracy score = 0.31121, Test accuracy score = 0.29769\nEpoch 6: Train Loss = 0.03057, Test Loss = 0.03034, Train accuracy score = 0.35108, Test accuracy score = 0.33910\nEpoch 7: Train Loss = 0.02989, Test Loss = 0.03000, Train accuracy score = 0.36253, Test accuracy score = 0.36347\nEpoch 8: Train Loss = 0.02947, Test Loss = 0.02903, Train accuracy score = 0.41801, Test accuracy score = 0.42584\nEpoch 9: Train Loss = 0.02944, Test Loss = 0.02979, Train accuracy score = 0.37478, Test accuracy score = 0.37762\nEpoch 10: Train Loss = 0.03026, Test Loss = 0.03092, Train accuracy score = 0.31053, Test accuracy score = 0.30451\nEpoch 11: Train Loss = 0.02983, Test Loss = 0.03009, Train accuracy score = 0.35445, Test accuracy score = 0.35928\nEpoch 12: Train Loss = 0.02984, Test Loss = 0.02979, Train accuracy score = 0.38881, Test accuracy score = 0.37762\nEpoch 13: Train Loss = 0.02955, Test Loss = 0.03046, Train accuracy score = 0.32704, Test accuracy score = 0.33569\nEpoch 14: Train Loss = 0.03000, Test Loss = 0.02957, Train accuracy score = 0.39870, Test accuracy score = 0.39203\nEpoch 15: Train Loss = 0.02939, Test Loss = 0.02905, Train accuracy score = 0.42195, Test accuracy score = 0.42558\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\npickle.dump(model, open('model_Hybrid.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:21:36.036673Z","iopub.execute_input":"2022-06-18T13:21:36.037545Z","iopub.status.idle":"2022-06-18T13:21:36.065902Z","shell.execute_reply.started":"2022-06-18T13:21:36.037504Z","shell.execute_reply":"2022-06-18T13:21:36.065109Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport pickle\n\nEmo = ['neutral','calm','happy','sad','angry','fear','disgust','surprise']\n\ndef extract_features(data,sample_rate):\n    result = np.array([])\n    \n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mfcc))\n    \n    # Log Mel-Spectrogram\n    mel = np.mean(librosa.feature.melspectrogram(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mel)) \n    \n    # Chroma\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S = np.abs(librosa.stft(data)), sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, chroma_stft))\n    \n    return result\n\ndef emotion_recognition(audio_file):\n    trained_model = pickle.load(open('model_Hybrid.pkl', 'rb'))\n    scaler = pickle.load(open('scaler_Hybrid-1.pkl','rb'))\n    \n    # load audio files with librosa\n    data, sample_rate = librosa.load(audio_file)\n    feat = extract_features(data,sample_rate)\n    feat = np.array(feat)\n    feat = feat[None,:]\n    sc_feat = scaler.transform(feat)\n    sc_feat = torch.from_numpy(sc_feat.astype('float32'))\n    prediction = trained_model(sc_feat.cuda())\n    pred = torch.argmax(prediction, dim=1)\n    return Emo[pred]","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:25:19.753076Z","iopub.execute_input":"2022-06-18T13:25:19.753554Z","iopub.status.idle":"2022-06-18T13:25:19.767803Z","shell.execute_reply.started":"2022-06-18T13:25:19.753513Z","shell.execute_reply":"2022-06-18T13:25:19.766591Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"audio_file = \"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-02-02-01-02-02.wav\"\nlabel = emotion_recognition(audio_file)\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:25:28.538819Z","iopub.execute_input":"2022-06-18T13:25:28.539186Z","iopub.status.idle":"2022-06-18T13:25:28.768255Z","shell.execute_reply.started":"2022-06-18T13:25:28.539159Z","shell.execute_reply":"2022-06-18T13:25:28.767451Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"disgust\n","output_type":"stream"}]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Two-Way Feature Extraction for Speech Emotion Recognition Using Deep Learning\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC8949356/","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\nfrom datetime import datetime\nimport pickle\n\nimport librosa\nimport librosa.display\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch import optim as opt\nfrom torch.utils.data import Dataset, DataLoader \nimport torchvision\nfrom torchvision import transforms as T, datasets  \nfrom torch.utils.tensorboard import SummaryWriter \n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:04.862742Z","iopub.execute_input":"2022-06-21T17:58:04.863258Z","iopub.status.idle":"2022-06-21T17:58:09.286147Z","shell.execute_reply.started":"2022-06-21T17:58:04.863167Z","shell.execute_reply":"2022-06-21T17:58:09.285287Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"Ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/\"\nTess = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:15.131943Z","iopub.execute_input":"2022-06-21T17:58:15.132818Z","iopub.status.idle":"2022-06-21T17:58:15.138658Z","shell.execute_reply.started":"2022-06-21T17:58:15.132777Z","shell.execute_reply":"2022-06-21T17:58:15.137804Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ravdess_directory_list = os.listdir(Ravdess)\nravdess_emotion = ['neutral','calm','happy','sad','angry','fear','disgust','surprise']\n\nfile_emotion = []\nfile_path = []\nfor dir in ravdess_directory_list:\n    if (dir == \"audio_speech_actors_01-24\"):\n        continue\n    actor = os.listdir(Ravdess + dir)\n    for file in actor:\n        # get the emotion of this file\n        part = file.split('.')[0]\n        part = part.split('-')\n        id = int(part[2])\n        file_emotion.append(ravdess_emotion[id-1])\n        # get file's path\n        file_path.append(Ravdess + dir + '/' + file)\n        \n# convert to dataframe\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\npath_df = pd.DataFrame(file_path, columns=['Path'])\nRavdess_df = pd.concat([emotion_df, path_df], axis=1)\n\nRavdess_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:17.266408Z","iopub.execute_input":"2022-06-21T17:58:17.266769Z","iopub.status.idle":"2022-06-21T17:58:17.638070Z","shell.execute_reply.started":"2022-06-21T17:58:17.266740Z","shell.execute_reply":"2022-06-21T17:58:17.637310Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1440, 2)"},"metadata":{}}]},{"cell_type":"code","source":"tess_directory_list = os.listdir(Tess)\n\nfile_emotion = []\nfile_path = []\n\nfor dir in tess_directory_list:\n    directories = os.listdir(Tess + dir)\n    for file in directories:\n        part = file.split('.')[0]\n        part = part.split('_')[2]\n        if part=='ps':\n            file_emotion.append('surprise')\n        else:\n            file_emotion.append(part)\n        file_path.append(Tess + dir + '/' + file)\n        \n# convert to dataframe\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\npath_df = pd.DataFrame(file_path, columns=['Path'])\nTess_df = pd.concat([emotion_df, path_df], axis=1)\n\nTess_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:19.675909Z","iopub.execute_input":"2022-06-21T17:58:19.676277Z","iopub.status.idle":"2022-06-21T17:58:20.402933Z","shell.execute_reply.started":"2022-06-21T17:58:19.676247Z","shell.execute_reply":"2022-06-21T17:58:20.402166Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(2800, 2)"},"metadata":{}}]},{"cell_type":"code","source":"data_path = pd.concat([Ravdess_df, Tess_df], axis = 0)\ndata_path.to_csv(\"data_path.csv\",index=False)\ndata_path.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:28.949252Z","iopub.execute_input":"2022-06-21T17:58:28.949688Z","iopub.status.idle":"2022-06-21T17:58:29.012486Z","shell.execute_reply.started":"2022-06-21T17:58:28.949650Z","shell.execute_reply":"2022-06-21T17:58:29.011625Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Emotions                                               Path\n0  surprise  /kaggle/input/ravdess-emotional-speech-audio/A...\n1   neutral  /kaggle/input/ravdess-emotional-speech-audio/A...\n2   disgust  /kaggle/input/ravdess-emotional-speech-audio/A...\n3   disgust  /kaggle/input/ravdess-emotional-speech-audio/A...\n4   neutral  /kaggle/input/ravdess-emotional-speech-audio/A...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>surprise</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def extract_features(data,sample_rate):\n    result = np.array([])\n    \n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mfcc))\n    \n    # Log Mel-Spectrogram\n    mel = np.mean(librosa.feature.melspectrogram(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mel)) \n    \n    # Chroma\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S = np.abs(librosa.stft(data)), sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, chroma_stft))\n    \n    # Spectral centroid\n    spec_centroid = np.mean(librosa.feature.spectral_centroid(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, spec_centroid))\n    \n    # Spectral rolloff\n    rolloff = np.mean(librosa.feature.spectral_rolloff(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, rolloff))\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:32.132705Z","iopub.execute_input":"2022-06-21T17:58:32.133050Z","iopub.status.idle":"2022-06-21T17:58:32.143443Z","shell.execute_reply.started":"2022-06-21T17:58:32.133023Z","shell.execute_reply":"2022-06-21T17:58:32.142171Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.03 * np.random.uniform() * np.amax(data)\n    data = data + noise_amp * np.random.normal(size = data.shape[0])\n    return data\n\ndef stretch(data, rate = 0.8):\n    return librosa.effects.time_stretch(data, rate)\n\ndef pitch(data, sampling_rate, pitch_factor = 0.7):\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:58:34.379396Z","iopub.execute_input":"2022-06-21T17:58:34.379825Z","iopub.status.idle":"2022-06-21T17:58:34.391917Z","shell.execute_reply.started":"2022-06-21T17:58:34.379789Z","shell.execute_reply":"2022-06-21T17:58:34.390948Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\nfor path, emotion in zip(data_path.Path, data_path.Emotions):\n    # load data\n    data, sample_rate = librosa.load(path, duration=3)\n    \n    # augmentation\n    noise_data = noise(data)\n    stretch_pitch_data = stretch(data)\n    stretch_pitch_data = pitch(stretch_pitch_data, sample_rate)\n    \n    # original speech\n    feature = extract_features(data, sample_rate)\n    feature = np.array(feature)\n    X.append(feature)\n    Y.append(emotion)\n    \n    # noise speech\n    feature_noise = extract_features(noise_data, sample_rate)\n    feature_noise = np.array(feature_noise)\n    X.append(feature_noise)\n    Y.append(emotion)\n    \n    # stretch and pitch speech\n    feature_stretch_pitch = extract_features(stretch_pitch_data, sample_rate)\n    feature_stretch_pitch = np.array(feature_stretch_pitch)\n    X.append(feature_stretch_pitch)\n    Y.append(emotion)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T09:32:33.477903Z","iopub.execute_input":"2022-06-18T09:32:33.478563Z","iopub.status.idle":"2022-06-18T10:01:40.585854Z","shell.execute_reply.started":"2022-06-18T09:32:33.478526Z","shell.execute_reply":"2022-06-18T10:01:40.584839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to df and save\nFeatures = pd.DataFrame(X)\nFeatures['labels'] = Y\nFeatures.to_csv('features.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:03:46.125141Z","iopub.execute_input":"2022-06-18T10:03:46.125884Z","iopub.status.idle":"2022-06-18T10:03:50.701703Z","shell.execute_reply.started":"2022-06-18T10:03:46.125848Z","shell.execute_reply":"2022-06-18T10:03:50.700758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load features from file\nFeatures = pd.read_csv(\"/kaggle/working/features.csv\")\n# Features = pd.read_csv(\"../input/fe2way/features.csv\")\nX = Features.iloc[: ,:-1].values\nY = Features['labels'].values\nlen(X), len(Y), data_path.Path.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:04.452039Z","iopub.execute_input":"2022-06-21T17:59:04.452563Z","iopub.status.idle":"2022-06-21T17:59:05.539437Z","shell.execute_reply.started":"2022-06-21T17:59:04.452522Z","shell.execute_reply":"2022-06-21T17:59:05.538482Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(12720, 12720, (4240,))"},"metadata":{}}]},{"cell_type":"code","source":"# One hot endcoding for Y.\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:10.547865Z","iopub.execute_input":"2022-06-21T17:59:10.548561Z","iopub.status.idle":"2022-06-21T17:59:10.557989Z","shell.execute_reply.started":"2022-06-21T17:59:10.548529Z","shell.execute_reply":"2022-06-21T17:59:10.557209Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, random_state = 0, shuffle = True, test_size=0.2)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:12.660422Z","iopub.execute_input":"2022-06-21T17:59:12.660917Z","iopub.status.idle":"2022-06-21T17:59:12.699543Z","shell.execute_reply.started":"2022-06-21T17:59:12.660888Z","shell.execute_reply":"2022-06-21T17:59:12.698313Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"((10176, 162), (10176, 8), (2544, 162), (2544, 8))"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\n\n# scaling our data and save the scaler\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\n\npickle.dump(scaler, open('scaler_two.pkl','wb'))\nscaler = pickle.load(open('scaler_two.pkl','rb'))\n\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:14.758010Z","iopub.execute_input":"2022-06-21T17:59:14.758510Z","iopub.status.idle":"2022-06-21T17:59:14.834581Z","shell.execute_reply.started":"2022-06-21T17:59:14.758467Z","shell.execute_reply":"2022-06-21T17:59:14.833800Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"((10176, 162), (10176, 8), (2544, 162), (2544, 8))"},"metadata":{}}]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        X = torch.tensor(self.X[idx]).type(torch.float)\n        y = torch.tensor(self.y[idx]).type(torch.float)\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:19.011394Z","iopub.execute_input":"2022-06-21T17:59:19.011743Z","iopub.status.idle":"2022-06-21T17:59:19.018493Z","shell.execute_reply.started":"2022-06-21T17:59:19.011715Z","shell.execute_reply":"2022-06-21T17:59:19.017133Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Convert X to tensor\nX_train_2 = torch.from_numpy(x_train)\nX_test_2 = torch.from_numpy(x_test)\nprint(X_train_2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:26.073515Z","iopub.execute_input":"2022-06-21T17:59:26.074324Z","iopub.status.idle":"2022-06-21T17:59:26.080376Z","shell.execute_reply.started":"2022-06-21T17:59:26.074290Z","shell.execute_reply":"2022-06-21T17:59:26.079429Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"torch.Size([10176, 162])\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 64\ntrain_data = Dataset(X_train_2, y_train)\ntest_data = Dataset(X_test_2, y_test)\n\ntrain_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:27.949522Z","iopub.execute_input":"2022-06-21T17:59:27.949956Z","iopub.status.idle":"2022-06-21T17:59:27.957147Z","shell.execute_reply.started":"2022-06-21T17:59:27.949916Z","shell.execute_reply":"2022-06-21T17:59:27.956141Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class DNN(nn.Module):\n    \n    def __init__(self, ):\n        super(DNN, self).__init__()\n        \n        # Block #1: \n        self.layer1 = nn.Sequential(\n            nn.Linear(in_features=162, out_features=1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.3)\n        )\n        \n        # Block #2: \n        self.layer2 = nn.Sequential(\n            nn.Linear(in_features=1024, out_features=512),\n            nn.ReLU(),\n            nn.Dropout(p=0.3)\n        )\n        \n        # Block #3: \n        self.layer3 = nn.Sequential(\n            nn.Linear(in_features=512, out_features=256),\n            nn.ReLU(),\n            nn.Dropout(p=0.3)\n        )\n        \n        # Block #4: \n        self.layer4 = nn.Sequential(\n            nn.Linear(in_features=256, out_features=128),\n            nn.ReLU(),\n            nn.Dropout(p=0.3)\n        )\n        \n        # Block #5: \n        self.layer5 = nn.Sequential(\n            nn.Linear(in_features=128, out_features=64),\n            nn.ReLU(),\n            nn.Dropout(p=0.2)\n        )\n        \n        # Block #6: \n        self.layer6 = nn.Sequential(\n            nn.Linear(in_features=64, out_features=32),\n            nn.ReLU(),\n            nn.Dropout(p=0.2)\n        )\n\n        # FC 8 → softmax\n        self.fc = nn.Linear(in_features=32, out_features=8)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        \n        # Channel x H = 1 x 162\n#         x = x.view(-1,80)\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        \n        out = self.fc(out)\n        out = self.softmax(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:59:29.971365Z","iopub.execute_input":"2022-06-21T17:59:29.971717Z","iopub.status.idle":"2022-06-21T17:59:29.984017Z","shell.execute_reply.started":"2022-06-21T17:59:29.971690Z","shell.execute_reply":"2022-06-21T17:59:29.982936Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model = DNN()\n# print(model)\n# model = CNN()\n# print(model)\n!pip install torch-summary\nfrom torchsummary import summary\n\nmodel = DNN()\nsummary(model, (64, 162))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T18:00:27.575864Z","iopub.execute_input":"2022-06-21T18:00:27.576250Z","iopub.status.idle":"2022-06-21T18:00:40.729169Z","shell.execute_reply.started":"2022-06-21T18:00:27.576217Z","shell.execute_reply":"2022-06-21T18:00:40.728077Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch-summary in /opt/conda/lib/python3.7/site-packages (1.4.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 64, 1024]            --\n|    └─Linear: 2-1                       [-1, 64, 1024]            166,912\n|    └─ReLU: 2-2                         [-1, 64, 1024]            --\n|    └─Dropout: 2-3                      [-1, 64, 1024]            --\n├─Sequential: 1-2                        [-1, 64, 512]             --\n|    └─Linear: 2-4                       [-1, 64, 512]             524,800\n|    └─ReLU: 2-5                         [-1, 64, 512]             --\n|    └─Dropout: 2-6                      [-1, 64, 512]             --\n├─Sequential: 1-3                        [-1, 64, 256]             --\n|    └─Linear: 2-7                       [-1, 64, 256]             131,328\n|    └─ReLU: 2-8                         [-1, 64, 256]             --\n|    └─Dropout: 2-9                      [-1, 64, 256]             --\n├─Sequential: 1-4                        [-1, 64, 128]             --\n|    └─Linear: 2-10                      [-1, 64, 128]             32,896\n|    └─ReLU: 2-11                        [-1, 64, 128]             --\n|    └─Dropout: 2-12                     [-1, 64, 128]             --\n├─Sequential: 1-5                        [-1, 64, 64]              --\n|    └─Linear: 2-13                      [-1, 64, 64]              8,256\n|    └─ReLU: 2-14                        [-1, 64, 64]              --\n|    └─Dropout: 2-15                     [-1, 64, 64]              --\n├─Sequential: 1-6                        [-1, 64, 32]              --\n|    └─Linear: 2-16                      [-1, 64, 32]              2,080\n|    └─ReLU: 2-17                        [-1, 64, 32]              --\n|    └─Dropout: 2-18                     [-1, 64, 32]              --\n├─Linear: 1-7                            [-1, 64, 8]               264\n├─Softmax: 1-8                           [-1, 64, 8]               --\n==========================================================================================\nTotal params: 866,536\nTrainable params: 866,536\nNon-trainable params: 0\nTotal mult-adds (M): 1.73\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 0.99\nParams size (MB): 3.31\nEstimated Total Size (MB): 4.33\n==========================================================================================\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 64, 1024]            --\n|    └─Linear: 2-1                       [-1, 64, 1024]            166,912\n|    └─ReLU: 2-2                         [-1, 64, 1024]            --\n|    └─Dropout: 2-3                      [-1, 64, 1024]            --\n├─Sequential: 1-2                        [-1, 64, 512]             --\n|    └─Linear: 2-4                       [-1, 64, 512]             524,800\n|    └─ReLU: 2-5                         [-1, 64, 512]             --\n|    └─Dropout: 2-6                      [-1, 64, 512]             --\n├─Sequential: 1-3                        [-1, 64, 256]             --\n|    └─Linear: 2-7                       [-1, 64, 256]             131,328\n|    └─ReLU: 2-8                         [-1, 64, 256]             --\n|    └─Dropout: 2-9                      [-1, 64, 256]             --\n├─Sequential: 1-4                        [-1, 64, 128]             --\n|    └─Linear: 2-10                      [-1, 64, 128]             32,896\n|    └─ReLU: 2-11                        [-1, 64, 128]             --\n|    └─Dropout: 2-12                     [-1, 64, 128]             --\n├─Sequential: 1-5                        [-1, 64, 64]              --\n|    └─Linear: 2-13                      [-1, 64, 64]              8,256\n|    └─ReLU: 2-14                        [-1, 64, 64]              --\n|    └─Dropout: 2-15                     [-1, 64, 64]              --\n├─Sequential: 1-6                        [-1, 64, 32]              --\n|    └─Linear: 2-16                      [-1, 64, 32]              2,080\n|    └─ReLU: 2-17                        [-1, 64, 32]              --\n|    └─Dropout: 2-18                     [-1, 64, 32]              --\n├─Linear: 1-7                            [-1, 64, 8]               264\n├─Softmax: 1-8                           [-1, 64, 8]               --\n==========================================================================================\nTotal params: 866,536\nTrainable params: 866,536\nNon-trainable params: 0\nTotal mult-adds (M): 1.73\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 0.99\nParams size (MB): 3.31\nEstimated Total Size (MB): 4.33\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nclass Trainer:\n    def __init__(self, train_dataloader, test_dataloader,\n                 model, loss_fn, optimizer, scheduler, logger, device='cpu'):\n        self.model = model.to(device)\n        self.train_dataloader = train_dataloader\n        self.test_dataloader = test_dataloader\n        self.logger = logger\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = device\n\n    def train_epoch(self):\n        # Train data\n        n_samples = len(self.train_dataloader.dataset)\n        train_loss = 0\n\n        for batch_idx, (X, y) in enumerate(self.train_dataloader):\n            X = X.to(self.device)\n            y = y.to(self.device)\n            # Forward\n            pred = self.model(X)\n            loss = self.loss_fn(pred, torch.argmax(y, dim=1))\n            \n            # Backward\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            train_loss += loss\n        self.scheduler.step()\n        return train_loss / n_samples\n\n    def test_epoch(self):\n        # Test data\n        n_samples = len(self.test_dataloader.dataset)\n        test_loss = 0\n\n        for batch_idx, (X,y) in enumerate(self.test_dataloader):\n            X = X.to(self.device)\n            y = y.to(self.device)\n            with torch.no_grad():\n                # Forward\n                pred = self.model(X)\n                loss = self.loss_fn(pred, torch.argmax(y, dim=1))\n\n            test_loss += loss\n\n        return test_loss / n_samples\n\n    def evaluation(self, dataloader):\n        y_true = []\n        y_pred = []\n        for X, y in dataloader:\n            X = X.to(self.device)\n            y_true.append(y.detach().cpu())\n            y_pred.append(self.model(X).detach().cpu())\n        \n        y_true = torch.cat(y_true, dim=0)\n        y_pred = torch.cat(y_pred, dim=0)\n\n        true_labels = torch.argmax(y_true, dim=1)\n        pred_labels = torch.argmax(y_pred, dim=1)\n        accuracy = accuracy_score(true_labels.cpu(), pred_labels.cpu())\n\n        return accuracy\n\n    def train(self, epochs=10):\n        for i in range(epochs):\n            self.current_epoch = i+1\n            # Training\n            train_loss = self.train_epoch()\n            test_loss = self.test_epoch()\n\n            # Evaluation\n            train_acc = self.evaluation(self.train_dataloader)\n            test_acc = self.evaluation(self.test_dataloader)\n            \n            # Logging\n            self.logger.add_scalar('Loss/train', train_loss.item(), i+1)\n            self.logger.add_scalar('Loss/test', test_loss.item(), i+1)\n            self.logger.add_scalar('Accuracy/train', train_acc.item(), i+1)\n            self.logger.add_scalar('Accuracy/test', test_acc.item(), i+1)\n\n            ## Log histogram\n            for name, params in model.named_parameters():\n                if 'weight' in name:\n                    self.logger.add_histogram(name, params, i+1)\n\n            # if ((i+1) % 10 == 0):\n            print(f\"Epoch {i+1}: Train Loss = {train_loss.item():.5f}, Test Loss = {test_loss.item():.5f}, \"\n            f\"Train accuracy score = {train_acc.item():.5f}, Test accuracy score = {test_acc.item():.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T18:07:29.596715Z","iopub.execute_input":"2022-06-21T18:07:29.597056Z","iopub.status.idle":"2022-06-21T18:07:29.640779Z","shell.execute_reply.started":"2022-06-21T18:07:29.597026Z","shell.execute_reply":"2022-06-21T18:07:29.639705Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 1e-3\nLOG_DIR = \"./logs/\"\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T18:07:32.859522Z","iopub.execute_input":"2022-06-21T18:07:32.859873Z","iopub.status.idle":"2022-06-21T18:07:32.866088Z","shell.execute_reply.started":"2022-06-21T18:07:32.859838Z","shell.execute_reply":"2022-06-21T18:07:32.865051Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\n\nmodel = DNN()\nloss_fn = nn.CrossEntropyLoss() \noptimizer = opt.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = opt.lr_scheduler.StepLR(optimizer, step_size=20, gamma=1, last_epoch=- 1, verbose=False)\nlogger = SummaryWriter(os.path.join(LOG_DIR, datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\"))) # Logger\n\n# Trainer\ntrainer = Trainer(\n    train_dataloader=train_dataloader,\n    test_dataloader=test_dataloader,\n    model=model,\n    loss_fn=loss_fn,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    logger=logger,\n    device=DEVICE\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T18:07:34.407978Z","iopub.execute_input":"2022-06-21T18:07:34.408597Z","iopub.status.idle":"2022-06-21T18:07:40.692301Z","shell.execute_reply.started":"2022-06-21T18:07:34.408564Z","shell.execute_reply":"2022-06-21T18:07:40.691356Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\ntrainer.train(epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T18:07:43.634776Z","iopub.execute_input":"2022-06-21T18:07:43.635145Z","iopub.status.idle":"2022-06-21T18:08:37.455334Z","shell.execute_reply.started":"2022-06-21T18:07:43.635091Z","shell.execute_reply":"2022-06-21T18:08:37.454090Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 0.02919, Test Loss = 0.02671, Train accuracy score = 0.54953, Test accuracy score = 0.55936\nEpoch 2: Train Loss = 0.02566, Test Loss = 0.02472, Train accuracy score = 0.70224, Test accuracy score = 0.69890\nEpoch 3: Train Loss = 0.02452, Test Loss = 0.02457, Train accuracy score = 0.70666, Test accuracy score = 0.70322\nEpoch 4: Train Loss = 0.02435, Test Loss = 0.02475, Train accuracy score = 0.71010, Test accuracy score = 0.69890\nEpoch 5: Train Loss = 0.02419, Test Loss = 0.02411, Train accuracy score = 0.74636, Test accuracy score = 0.74057\nEpoch 6: Train Loss = 0.02402, Test Loss = 0.02401, Train accuracy score = 0.75393, Test accuracy score = 0.75354\nEpoch 7: Train Loss = 0.02412, Test Loss = 0.02468, Train accuracy score = 0.69684, Test accuracy score = 0.70283\nEpoch 8: Train Loss = 0.02398, Test Loss = 0.02421, Train accuracy score = 0.74184, Test accuracy score = 0.73310\nEpoch 9: Train Loss = 0.02411, Test Loss = 0.02399, Train accuracy score = 0.74941, Test accuracy score = 0.74175\nEpoch 10: Train Loss = 0.02409, Test Loss = 0.02427, Train accuracy score = 0.74499, Test accuracy score = 0.72484\nEpoch 11: Train Loss = 0.02394, Test Loss = 0.02415, Train accuracy score = 0.74106, Test accuracy score = 0.73781\nEpoch 12: Train Loss = 0.02394, Test Loss = 0.02393, Train accuracy score = 0.75894, Test accuracy score = 0.76022\nEpoch 13: Train Loss = 0.02385, Test Loss = 0.02403, Train accuracy score = 0.75246, Test accuracy score = 0.73899\nEpoch 14: Train Loss = 0.02385, Test Loss = 0.02419, Train accuracy score = 0.74027, Test accuracy score = 0.73349\nEpoch 15: Train Loss = 0.02394, Test Loss = 0.02393, Train accuracy score = 0.75708, Test accuracy score = 0.75000\nEpoch 16: Train Loss = 0.02369, Test Loss = 0.02409, Train accuracy score = 0.73516, Test accuracy score = 0.73664\nEpoch 17: Train Loss = 0.02372, Test Loss = 0.02383, Train accuracy score = 0.76582, Test accuracy score = 0.75904\nEpoch 18: Train Loss = 0.02368, Test Loss = 0.02389, Train accuracy score = 0.76789, Test accuracy score = 0.76612\nEpoch 19: Train Loss = 0.02383, Test Loss = 0.02403, Train accuracy score = 0.74912, Test accuracy score = 0.74057\nEpoch 20: Train Loss = 0.02362, Test Loss = 0.02430, Train accuracy score = 0.73103, Test accuracy score = 0.73192\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\npickle.dump(model, open('model_two.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:29:22.743866Z","iopub.execute_input":"2022-06-18T10:29:22.744274Z","iopub.status.idle":"2022-06-18T10:29:22.759682Z","shell.execute_reply.started":"2022-06-18T10:29:22.744238Z","shell.execute_reply":"2022-06-18T10:29:22.758877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport pickle\n\nEmo = ['neutral','calm','happy','sad','angry','fear','disgust','surprise']\n\ndef extract_features(data,sample_rate):\n    result = np.array([])\n    \n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mfcc))\n    \n    # Log Mel-Spectrogram\n    mel = np.mean(librosa.feature.melspectrogram(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, mel)) \n    \n    # Chroma\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S = np.abs(librosa.stft(data)), sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, chroma_stft))\n    \n    # Spectral centroid\n    spec_centroid = np.mean(librosa.feature.spectral_centroid(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, spec_centroid))\n    \n    # Spectral rolloff\n    rolloff = np.mean(librosa.feature.spectral_rolloff(y = data, sr = sample_rate).T, axis = 0)\n    result = np.hstack((result, rolloff))\n    \n    return result\n\ndef emotion_recognition(audio_file):\n    trained_model = pickle.load(open('model_two.pkl', 'rb'))\n    scaler = pickle.load(open('scaler_two.pkl','rb'))\n    \n    # load audio files with librosa\n    data, sample_rate = librosa.load(audio_file)\n    feat = extract_features(data,sample_rate)\n    feat = np.array(feat)\n    feat = feat[None,:]\n    sc_feat = scaler.transform(feat)\n    sc_feat = torch.from_numpy(sc_feat.astype('float32'))\n    prediction = trained_model(sc_feat.cuda())\n    pred = torch.argmax(prediction, dim=1)\n    return Emo[pred]","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:29:26.368024Z","iopub.execute_input":"2022-06-18T10:29:26.368637Z","iopub.status.idle":"2022-06-18T10:29:26.38079Z","shell.execute_reply.started":"2022-06-18T10:29:26.3686Z","shell.execute_reply":"2022-06-18T10:29:26.380014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_file = \"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-02-02-01-02-02.wav\"\nlabel = emotion_recognition(audio_file)\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:29:29.533055Z","iopub.execute_input":"2022-06-18T10:29:29.533677Z","iopub.status.idle":"2022-06-18T10:29:29.776352Z","shell.execute_reply.started":"2022-06-18T10:29:29.533639Z","shell.execute_reply":"2022-06-18T10:29:29.775561Z"},"trusted":true},"execution_count":null,"outputs":[]}]}